{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fded102b",
   "metadata": {},
   "source": [
    "# 5 Stages of Summarization: From Beginner to Expert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab8b2cf",
   "metadata": {},
   "source": [
    "Summarization is a vital component of many LLM tasks. In practical scenarios, you'll run into use cases where turning extensive texts into concise, meaningful points is essential.\n",
    "\n",
    "Depending on the text's length you're addressing, various summarization techniques can be applied.\n",
    "\n",
    "Here, we'll outline 5 distinct levels of summarization, ranging from basic to advanced. Remember, these aren't the only methods out there.\n",
    "\n",
    "**5 Levels Of Summarization:**\n",
    "Summarize a few sentences - Basic Prompt\n",
    "Summarize several paragraphs - Prompt Templates\n",
    "Summarize a few pages - Map Reduce\n",
    "Summarize a whole book - Best Representation Vectors\n",
    "Summarize text of an indeterminate length - Agents.\n",
    "1. **Summarize a few sentences** - Basic Prompt \n",
    "2. **Summarize several paragraphs** - Prompt Templates \n",
    "3. **Summarize a few pages** - Map Reduce \n",
    "4. **Summarize a few pages** - Recurssive Map Reduce\n",
    "5. **Summarize a whole book** - Best Representation Vectors\n",
    "\n",
    "Stay tuned for level 6 \n",
    "First, let's import our Konko API key from a .dotenv file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f611fa21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv,find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342796d0",
   "metadata": {},
   "source": [
    "## Level 1: Basic Prompt - Summarize a few sentences\n",
    "\n",
    "If you're looking to briefly summarize just a few sentences, you can simply use a direct prompt and then copy and paste your text.\n",
    "\n",
    "**Summarizing JIRA Tickets:**\n",
    "\n",
    "Businesses often drown in many JIRA tickets, overwhelming teams. Summarizing helps quickly grasp each ticket's essence amid the chaos. \n",
    "\n",
    "However, this method isn't scalable and is best suited for limited scenarios, fitting perfectly as level #1!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a6ea241",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatKonko\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "538ded7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatKonko(model='meta-llama/Llama-2-70b-chat-hf', max_tokens = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18ca4b1",
   "metadata": {},
   "source": [
    "The crucial step is giving clear directions to the LLM, guiding its action. Here, I'm instructing the model to produce a summary of the following Jira Ticket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67146e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful assistant.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"\"\"\n",
    "                    Could you, in your eloquent way, condense this ticket's story for us?\n",
    "\n",
    "                    Ticket Content:\n",
    "                    Ticket ID: JIRA-78901\n",
    "                    Title: Implement Dynamic Cache Refresh Mechanism\n",
    "                    Reporter: Alex Thompson\n",
    "                    Assigned to: Jamie Cortez\n",
    "                    Status: Open\n",
    "                    Priority: High\n",
    "                    Description:\n",
    "                    Over the past few months, our XYZ product's analytics has shown a 25% decrease in response time, especially during peak usage hours. Analysis attributes this to cache bottlenecks, which are affecting user satisfaction scores and leading to an uptick in support tickets. This ticket proposes the development of a dynamic cache refresh mechanism. The intent is to have a smarter cache system that intelligently adjusts refresh rates based on real-time traffic loads and query complexities. By doing so, we aim to enhance server responsiveness, ensuring users have a seamless experience. This mechanism should also provide admin users with an interface to set manual overrides if needed. It's imperative that this solution seamlessly integrates with our current Redis setup and be scalable for future growth.\n",
    "\n",
    "                    Dependencies:\n",
    "\n",
    "                    Completion of ticket JIRA-78890 (Upgrade to Redis 7.0).\n",
    "                    Integration testing with the recently introduced user analytics module.\n",
    "                    Coordination with the database team and DevOps for deployment considerations.\n",
    "                    Comments:\n",
    "                    John Doe: Keep in mind our scheduled maintenance on the 20th. We shouldn’t have overlapping activities.\n",
    "                    Lucy Green: QA team will require documentation on the new features to ensure comprehensive testing. Expecting at least 3 days for complete QA post-implementation.\n",
    "                    Carlos Mendoza: Has anyone considered the impact on our mobile users? We need to ensure the changes are optimized for both desktop and mobile platforms.\n",
    "\n",
    "\"\"\"\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61522722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sure, here's a condensed version of the ticket's story:\n",
      "\n",
      "The XYZ product's response time has decreased by 25% over the past few months, especially during peak hours, due to cache bottlenecks. This ticket proposes the development of a dynamic cache refresh mechanism to address the issue, which will adjust refresh rates based on real-time traffic loads and query complexities. The solution should integrate with the current Redis setup, be scalable for future growth, and provide admin users with an interface to set manual overrides if needed. The dependencies for this ticket include the completion of ticket JIRA-78890 (Upgrade to Redis 7.0), integration testing with the recently introduced user analytics module, and coordination with the database team and DevOps for deployment considerations.\n",
      "\n",
      "Additionally, the QA team will require documentation on the new features for comprehensive testing, and the changes should be optimized for both desktop and mobile platforms. The implementation should not overlap with the scheduled maintenance on the 20th.\n"
     ]
    }
   ],
   "source": [
    "output = llm(messages)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133d1b40",
   "metadata": {},
   "source": [
    "**The summary, though condensed, remains detailed for quick reads. We need a shorter version focusing on key points. Let's tweak our prompt for a clearer, concise snapshot without unnecessary specifics.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ece0c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful assistant.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"\"\"\n",
    "                    Could you, in your eloquent way, condense this ticket's story for us? Our tech team would love a concise summary, highlighting:\n",
    "                    1. The core issue or feature being addressed.\n",
    "                    2. The primary expected outcomes.\n",
    "                    3. Any crucial dependencies or constraints.\n",
    "                    4. The urgency or priority level.\n",
    "\n",
    "                    Ticket Content:\n",
    "                    Ticket ID: JIRA-78901\n",
    "                    Title: Implement Dynamic Cache Refresh Mechanism\n",
    "                    Status: Open\n",
    "                    Priority: High\n",
    "                    Description:\n",
    "                    Over the past few months, our XYZ product's analytics has shown a 25% decrease in response time, especially during peak usage hours. Analysis attributes this to cache bottlenecks, which are affecting user satisfaction scores and leading to an uptick in support tickets. This ticket proposes the development of a dynamic cache refresh mechanism. The intent is to have a smarter cache system that intelligently adjusts refresh rates based on real-time traffic loads and query complexities. By doing so, we aim to enhance server responsiveness, ensuring users have a seamless experience. This mechanism should also provide admin users with an interface to set manual overrides if needed. It's imperative that this solution seamlessly integrates with our current Redis setup and be scalable for future growth.\n",
    "\n",
    "                    Dependencies:\n",
    "\n",
    "                    Completion of ticket JIRA-78890 (Upgrade to Redis 7.0).\n",
    "                    Integration testing with the recently introduced user analytics module.\n",
    "                    Coordination with the database team and DevOps for deployment considerations.\n",
    "                    Comments:\n",
    "                    John Doe: Keep in mind our scheduled maintenance on the 20th. We shouldn’t have overlapping activities.\n",
    "                    Lucy Green: QA team will require documentation on the new features to ensure comprehensive testing. Expecting at least 3 days for complete QA post-implementation.\n",
    "                    Carlos Mendoza: Has anyone considered the impact on our mobile users? We need to ensure the changes are optimized for both desktop and mobile platforms.\n",
    "\n",
    "\"\"\"\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68f9b501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sure, here's a concise summary of the ticket's story:\n",
      "\n",
      "1. Core issue/feature: Implement a dynamic cache refresh mechanism to address cache bottlenecks, reduce response time, and improve user satisfaction.\n",
      "2. Primary expected outcomes: Enhanced server responsiveness, seamless user experience, and an admin interface for manual overrides.\n",
      "3. Crucial dependencies/constraints:\n",
      "\t* Completion of ticket JIRA-78890 (Upgrade to Redis 7.0)\n",
      "\t* Integration testing with the recently introduced user analytics module\n",
      "\t* Coordination with the database team and DevOps for deployment considerations\n",
      "\t* Consideration of impact on mobile users\n",
      "4. Urgency/priority level: High priority, as the issue is affecting user satisfaction and leading to an increase in support tickets.\n",
      "\n",
      "I hope this summary helps your tech team understand the key aspects of the ticket!\n"
     ]
    }
   ],
   "source": [
    "output = llm(messages)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f294999",
   "metadata": {},
   "source": [
    "Nice! That's much better, but let's look at something we can automate a bit more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f1cf66",
   "metadata": {},
   "source": [
    "## Level 2: Prompt Templates - Summarize a few paragraphs\n",
    "\n",
    "Prompt templates are an effective method to dynamically insert specific text segments into your prompts. Think of them as akin to [Python f-strings](https://realpython.com/python-f-strings/), but tailored for seamless integration with language models.\n",
    "\n",
    "Let's delve into 2 short business documents: one about a **staff training memo** (representing \"Training and Onboarding\") and the other concerning a **yearly financial report** (representing \"Investor Relations\").\n",
    "\n",
    "While we have demonstrated the utility with these two specific scenarios, the potential applications are vast. For instance:\n",
    "\n",
    "1. **Customer Support:** Extract key issues from feedback to enhance product or service offerings.\n",
    "2. **Executive Briefings:** Create concise summaries for top decision-makers to grasp essential details without wading through extensive reports.\n",
    "3. **Product Reviews:** Summarize feedback on new product launches to quickly gauge customer sentiment and identify areas for improvement.\n",
    "4. **Market Research:** Collate insights about the latest industry trends and competitor activities in a brief format for strategic planning.\n",
    "\n",
    "By understanding the context and objectives, users can modify and tailor these templates to suit a wide array of business needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "712acb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b326aaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "paul_graham_essays = ['../data/memo/Onboarding_doc.txt', '../data/memo/Investor_relations.txt']\n",
    "\n",
    "essays = []\n",
    "\n",
    "for file_name in paul_graham_essays:\n",
    "    with open(file_name, 'r') as file:\n",
    "        essays.append(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529ad7c1",
   "metadata": {},
   "source": [
    "Let's print out a preview of the essays to see what they look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7d93873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essay #1: Training and Onboarding\n",
      "\n",
      "Our onboarding program for the Design Department has been formulated with extensive research and insights from current and past employees. The first week is dedicated to understanding the company’s history, mission, vision, and core values. We ensure this through a series of\n",
      "\n",
      "Essay #2: Investor relations report\n",
      "\n",
      "In the annual overview for 2022, XYZ has shown remarkable resilience and growth despite the challenges posed by the global landscape. Beginning with our achievements, XYZ's revenue surged by 25%, outpacing our closest competitors. This impressive growth can be attributed t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, essay in enumerate(essays):\n",
    "    print (f\"Essay #{i+1}: {essay[:300]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e70a48e",
   "metadata": {},
   "source": [
    "Next let's create a prompt template which will hold our instructions and a placeholder for the essay. In this illustration, we'll focus on extracting the core details, accomplishments, hurdles, and forthcoming plans or tactics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "946c379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Summarize the key achievements, main challenges faced, and any forward-looking strategies or \n",
    "initiatives mentioned in the document.\n",
    "\n",
    "{essay}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"essay\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b2611b",
   "metadata": {},
   "source": [
    "Then let's loop through the 2 essays and pass them to our LLM. I'm applying .strip() on the summaries to remove the white space on the front and back of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2038feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This prompt + essay has 395 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:  The document describes the training and onboarding program for the Design Department at a company. The program lasts for four weeks and covers various topics, including company history, mission, and values, department-specific tools and practices, collaboration, and individual role-specific training. The program also includes soft skills training and feedback sessions.\n",
      "\n",
      "Key achievements:\n",
      "\n",
      "* The program has been formulated with extensive research and insights from current and past employees.\n",
      "* New hires have expressed high satisfaction with the mentorship program and hands-on approach.\n",
      "* 80% of new hires feel confident to start real projects by the end of the third week.\n",
      "\n",
      "Main challenges:\n",
      "\n",
      "* Some new hires have expressed a desire for more advanced workshops on emerging design tools.\n",
      "* There is a suggestion to have a few sessions dedicated solely to understanding user research and integrating findings into the design.\n",
      "\n",
      "Forward-looking strategies/initiatives:\n",
      "\n",
      "* None mentioned in the document.\n",
      "\n",
      "\n",
      "This prompt + essay has 324 tokens\n",
      "Summary:  Key Achievements:\n",
      "\n",
      "* 25% revenue growth, outpacing competitors\n",
      "* Successful entry into the Asian market, with doubled sales in the last quarter\n",
      "* Launch of three innovative products, expanding intellectual property portfolio\n",
      "\n",
      "Main Challenges:\n",
      "\n",
      "* Supply chain disruptions, resulting in 5% decline in production capacity\n",
      "* Unexpected resignations in senior management, requiring strategy realignments\n",
      "\n",
      "Forward-Looking Strategies/Initiatives:\n",
      "\n",
      "* Investment in green technologies, projecting a 15% revenue increase by 2024\n",
      "* Exploration of potential mergers and acquisitions to strengthen European market presence\n",
      "* Quarterly investor meetings for greater transparency and stronger relationships\n",
      "\n",
      "Investor Feedback:\n",
      "\n",
      "* Positive feedback on adaptability and growth in turbulent times\n",
      "* Concerns regarding tech sector volatility and desire for risk mitigation strategies\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for essay in essays:\n",
    "    summary_prompt = prompt.format(essay=essay)\n",
    "    num_tokens = llm.get_num_tokens(summary_prompt)\n",
    "    print (f\"This prompt + essay has {num_tokens} tokens\")\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful assistant.\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=summary_prompt\n",
    "        ),\n",
    "    ]\n",
    "    summary = llm(messages)\n",
    "    \n",
    "    print (f\"Summary: {summary.content}\")\n",
    "    print (\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ae9a41",
   "metadata": {},
   "source": [
    "## Level 3: Map Reduce - Summarize a few pages \n",
    "\n",
    "**Why Summarize?**\n",
    "Summarizing large reports, like the \"Market report of The individual health insurance market in 2023,\" provides quick insights for businesses. It aids in:\n",
    "\n",
    "1. Faster decision-making.\n",
    "2. Clear stakeholder communication.\n",
    "3. Efficient meeting preparations.\n",
    "4. Sharing insights across teams.\n",
    "\n",
    "\n",
    "If you have multiple pages you'd like to summarize, you'll likely run into a token limit. Token limits won't always be a problem, but it is good to know how to handle them if you run into the issue.\n",
    "\n",
    "The chain type \"Map Reduce\" is a method that helps with this. You first generate a summary of smaller chunks (that fit within the token limit) and then you get a summary of the summaries.\n",
    "\n",
    "Check out [this video](https://www.youtube.com/watch?v=f9_BWhCI4Zo) for more information on how chain types work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2ce6270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c70352ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_essay = '../data/MarketReport_healthInsurance_originalVersion.txt'\n",
    "\n",
    "with open(market_essay, 'r') as file:\n",
    "    essay = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6de34d",
   "metadata": {},
   "source": [
    "Let's see how many tokens are in this essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b133938a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2587"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(essay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8ec39d",
   "metadata": {},
   "source": [
    "That's too many, let's split our text up into chunks so they fit into the prompt limit. I'm going a chunk size of 8,000 characters. \n",
    "\n",
    "> You can think of tokens as pieces of words used for natural language processing. For English text, **1 token is approximately 4 characters** or 0.75 words. As a point of reference, the collected works of Shakespeare are about 900,000 words or 1.2M tokens.\n",
    "\n",
    "This means the number of tokens we should expect is 8000 / 4 = ~ 2000 token chunks. But this will vary, each body of text/code will be different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e7c372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\"], chunk_size=8000, chunk_overlap=300)\n",
    "\n",
    "docs = text_splitter.create_documents([essay])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f66569f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we have 2 documents and the first one has 1621 tokens\n"
     ]
    }
   ],
   "source": [
    "num_docs = len(docs)\n",
    "\n",
    "num_tokens_first_doc = llm.get_num_tokens(docs[0].page_content)\n",
    "\n",
    "print (f\"Now we have {num_docs} documents and the first one has {num_tokens_first_doc} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61d49f5",
   "metadata": {},
   "source": [
    "Great, assuming that number of tokens is consistent in the other docs we should be good to go. Let's use LangChain's [load_summarize_chain](https://python.langchain.com/en/latest/use_cases/summarization.html) to do the `map_reducing` for us. We first need to initialize our chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f933f1f",
   "metadata": {},
   "source": [
    "**Determine Your Output Format**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb6f653",
   "metadata": {},
   "source": [
    "Want a bullet-point summary? Tailor your prompts accordingly. By using custom prompts, you can instruct the model with precision.\n",
    "\n",
    "Here's a peek into setting up those prompts:\n",
    "\n",
    "**Map Prompt:** This will remain consistent for mapping. The goal? To achieve a concise summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7442e889",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_prompt = \"\"\"\n",
    "Write a concise summary of the following:\n",
    "\"{text}\"\n",
    "CONCISE SUMMARY:\n",
    "\"\"\"\n",
    "map_prompt_template = PromptTemplate(template=map_prompt, input_variables=[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e908f0d6",
   "metadata": {},
   "source": [
    "**Combine Prompt:** This is where the magic of combining happens. For our goal, we want to refine and compile our mapped summaries into bullet points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f42deb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_prompt = \"\"\"\n",
    "Write a concise summary of the following text delimited by triple backquotes.\n",
    "Return your response in bullet points which covers the key points of the text.\n",
    "```{text}```\n",
    "BULLET POINT SUMMARY:\n",
    "\"\"\"\n",
    "combine_prompt_template = PromptTemplate(template=combine_prompt, input_variables=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2051818",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_chain = load_summarize_chain(llm=llm,\n",
    "                                     chain_type='map_reduce',\n",
    "                                     map_prompt=map_prompt_template,\n",
    "                                     combine_prompt=combine_prompt_template\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c986230f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    }
   ],
   "source": [
    "output = summary_chain.run(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4303ff",
   "metadata": {},
   "source": [
    "**Here is the summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e90a8582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * In 2023, the individual health insurance market has seen significant growth, with over 3.6 million new consumers entering the market.\n",
      "* Insurer participation has continued to grow, with national insurers expanding their participation the most.\n",
      "* Consumers have more choices in product offerings, with insurers offering 17% more plan options in 2023 than in 2022.\n",
      "* Premiums have increased modestly, with a median increase of 4% for the lowest-price silver plan.\n",
      "* The proportion of counties with a single insurer has decreased, and the number of plans available to consumers has increased.\n",
      "* Premiums have increased across all metal tiers and plan categories, with the highest increases for platinum and catastrophic plans.\n",
      "* National insurers have improved their price position in 2023, offering the lowest premiums for silver plans for 20% of consumers.\n",
      "* Insurtechs have seen a decrease in price leadership.\n",
      "* Medicaid and Blues plans maintain the highest proportion of price leadership, offering the lowest-cost option for 30% and 25% of consumers, respectively.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a76f478",
   "metadata": {},
   "source": [
    "## Level 4: Summarize a few pages - Recurssive Map Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f26d07",
   "metadata": {},
   "source": [
    "While the above summarization technique appears effective, it's essential to recognize some inherent challenges. Below, we outline these issues and propose solutions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030e1f72",
   "metadata": {},
   "source": [
    "**Current Challenge:**\n",
    "\n",
    "LangChain's 'Map Reduce' breaks down and summarizes content segments. However, the issue arises during the final summarization stage, when these summarized parts are consolidated, particularly for lengthy documents. This process can often surpass the token limit.\n",
    "\n",
    "We're now delving into a custom approach for iterative summarization. While our method offers benefits, it's important to highlight its inherent constraints, which we'll discuss further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a907955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "MAX_TOKENS_SUMMARY = 1000\n",
    "SUMMARY_SYS_MSG = \"\"\"Write a concise summary of the following:\n",
    "\"{input}\"\n",
    "CONCISE SUMMARY:\"\"\"\n",
    "\n",
    "FINAL_SUMMARY_SYS_MSG = \"\"\"\n",
    "Write a concise summary of the following text delimited by triple backquotes.\n",
    "Return your response in bullet points which covers the key points of the text.\n",
    "```{input}```\n",
    "BULLET POINT SUMMARY:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def token_len(input: str) -> int:\n",
    "    \"\"\"Get token length\"\"\"\n",
    "    return llm.get_num_tokens(input)\n",
    "\n",
    "def chunk(input: str) -> list:\n",
    "    input_tokens = token_len(input)\n",
    "    count = math.ceil(input_tokens / MAX_TOKENS_SUMMARY)\n",
    "    k, m = divmod(len(input), count)\n",
    "    chunks = [\n",
    "        input[i * k + min(i, m) : (i + 1) * k + min(i + 1, m)] for i in range(count)\n",
    "    ]\n",
    "    return chunks\n",
    "\n",
    "def summarize(input: str, final: bool = False) -> str:\n",
    "    if token_len(input) <= MAX_TOKENS_SUMMARY:\n",
    "        final = True  # Force bullet points if within token limit\n",
    "\n",
    "    # Use appropriate system message based on final flag\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\n",
    "        template=FINAL_SUMMARY_SYS_MSG if final else SUMMARY_SYS_MSG\n",
    "    )\n",
    "    human_message = HumanMessagePromptTemplate.from_template(\n",
    "        template=\"Input: {input}\"\n",
    "    )\n",
    "\n",
    "    if final:  # Directly summarize with bullet points if final flag is set\n",
    "        prompt = ChatPromptTemplate(\n",
    "            input_variables=[\"input\"],\n",
    "            messages=[system_message, human_message],\n",
    "        )\n",
    "        _input = prompt.format_prompt(input=input)\n",
    "        single_string_prompt = (_input.to_messages()[0].content)\n",
    "        single_string_prompt = [\n",
    "                                    SystemMessage(\n",
    "                                        content=\"You are a helpful assistant.\"\n",
    "                                    ),\n",
    "                                    HumanMessage(\n",
    "                                        content=single_string_prompt\n",
    "                                    ),\n",
    "                                ]\n",
    "        output = llm(single_string_prompt)\n",
    "        return output\n",
    "\n",
    "    # If not 'final', proceed with chunk-wise summarization\n",
    "    chunks = chunk(input=input)\n",
    "    summary = \"\"\n",
    "\n",
    "    for i in chunks:\n",
    "        prompt = ChatPromptTemplate(\n",
    "            input_variables=[\"input\"],\n",
    "            messages=[system_message, human_message],\n",
    "        )\n",
    "\n",
    "        _input = prompt.format_prompt(input=i)\n",
    "        single_string_prompt = (_input.to_messages()[0].content)\n",
    "        single_string_prompt = [\n",
    "                                    SystemMessage(\n",
    "                                        content=\"You are a helpful assistant.\"\n",
    "                                    ),\n",
    "                                    HumanMessage(\n",
    "                                        content=single_string_prompt\n",
    "                                    ),\n",
    "                                ]\n",
    "        output = llm(single_string_prompt)\n",
    "        summary += f\"\\n{output}\"\n",
    "\n",
    "    # Check token length of the summary and decide next step\n",
    "    sum_tokens = token_len(input=summary)\n",
    "\n",
    "    if sum_tokens > MAX_TOKENS_SUMMARY:\n",
    "        return summarize(input=summary, final=True)  # Recur with 'final' set to True\n",
    "\n",
    "    return summarize(input=summary, final=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97c4bf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_essay = '../data/MarketReport_healthInsurance_shortVersion.txt'\n",
    "\n",
    "with open(market_essay, 'r') as file:\n",
    "    essay = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe01711",
   "metadata": {},
   "source": [
    "Let's see how many tokens are in this essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74e75383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6196"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(essay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f65c11",
   "metadata": {},
   "source": [
    "**Let's examine the summary generated by our tailored method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "334576f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    }
   ],
   "source": [
    "output = summarize(essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be5fed7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * The Federal Insurance Office (FIO) within the US Department of the Treasury has released its annual report, detailing its activities and efforts to promote consumer protection and maintain insurance industry stability.\n",
      "* The report highlights FIO's contributions to the Financial Stability Oversight Council (FSOC) and its work on climate-related financial risks.\n",
      "* FIO has been engaged in various international forums, such as the Joint Committee under the U.S.-EU Covered Agreement and the Sustainable Insurance Forum (SIF).\n",
      "* FIO has requested information on climate-related risks and the insurance sector and has proposed revisions to the annual TRIP data call to improve its evaluation of cyber insurance.\n",
      "* FIO has been actively engaging with various stakeholders, including organizations, affiliates, members, supporters, and individuals, to gather input on climate-related financial risks in the insurance sector.\n",
      "* FIO has also been working on modernizing and reorganizing surety regulations, and has conducted its annual data call in connection with the Terrorism Risk Insurance Program (TRIP).\n",
      "* The report also mentions FIO's participation in the Federal Advisory Committee on Insurance (FACI) and its initial observations on the responses to its request for information on climate-related risks.\n",
      "* FIO has announced its intention to publish a climate report by the end of 2022, focusing on insurance supervision and regulation of climate-related financial risks.\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86a0539",
   "metadata": {},
   "source": [
    "Looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a6da87",
   "metadata": {},
   "source": [
    "## Level 5: Best Representation Vectors - Summarize an entire book\n",
    "\n",
    "As we navigate the intricacies of document summarization, it's evident that traditional methods, though robust in many scenarios, possess specific challenges. Let's briefly revisit these:\n",
    "\n",
    "1. Recursive Summarization:\n",
    "\n",
    "    **Function:** It partitions lengthy documents into digestible sections, which are individually summarized. These summaries are then amalgamated and further refined, iterating until a concise version surfaces.\n",
    "\n",
    "    **Shortcomings:**\n",
    "        1. Interrupted Logical Flow: Certain tools, such as LangChain, might split content without preserving its natural continuity.\n",
    "        2. Inconsistent Point Emphasis: The varied lengths of distinct points by authors can result in pivotal information being cut short or inadequately summarized.\n",
    "        \n",
    "    \n",
    "2. The 'Refine' Method:\n",
    "\n",
    "    **Function:** It incrementally improves summaries as more content is processed.\n",
    "\n",
    "    **Shortcomings:**\n",
    "        1. Inefficiency: Unlike recursive methods which leverage logarithmic time, this method proceeds linearly.\n",
    "        2. Bias Towards Initial Content: Preliminary segments may disproportionately influence the summary, even if they're unrelated to the main content.\n",
    "    \n",
    "Despite advances in language models, it's clear that some level of document segmentation and recursive summarization will always be necessary, especially for voluminous texts.\n",
    "\n",
    "In the upcoming section, we'll introduce an approach that seeks to address these challenges, ensuring coherent and meaningful summaries.\n",
    "\n",
    "We will be distilling expansive documents like \"The Economic Potential of Generative AI.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6ed1dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load the book\n",
    "loader = PyPDFLoader(\"../data/the-economic-potential-of-generative-ai-the-next-productivity-frontier-vf.pdf\")\n",
    "pages = loader.load()\n",
    "\n",
    "# Combine the pages, and replace the tabs with spaces\n",
    "text = \"\"\n",
    "\n",
    "for page in pages:\n",
    "    text += page.page_content\n",
    "    \n",
    "text = text.replace('\\t', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6db88712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This book has 31463 tokens in it\n"
     ]
    }
   ],
   "source": [
    "num_tokens = llm.get_num_tokens(text)\n",
    "\n",
    "print (f\"This book has {num_tokens} tokens in it\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bedfe55",
   "metadata": {},
   "source": [
    "Handling a vast 33K tokens exceeds even GPT's 32K capacity, and with a cost of $1.00 for the prompt, we need an efficient approach. \n",
    "\n",
    "**Objective**: Distill the book's essence through strategic chunking.\n",
    "\n",
    "- **Chunk & Embed**: Divide the book into significant sections and transform them into vectors using embeddings.\n",
    "  \n",
    "- **Diversify**: Opt for a blend of chunks providing both a holistic and varied book perspective. Consider: Which 10 passages best encapsulate the book's essence?\n",
    "  \n",
    "- **Clustering & Selection**: Group similar vectors, pinpointing the ones that most exemplify each cluster, and subsequently summarize these selected portions.\n",
    "  \n",
    "- **End Goal**: Create a compelling summary that, while potentially losing some detail, captures the primary content.\n",
    "\n",
    "Remember, this is a tailored approach, not the definitive solution. And yes, summarizing an entire book always entails some loss of detail!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e0e930b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d3d233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\", \"\\t\"], chunk_size=8000, chunk_overlap=800)\n",
    "\n",
    "docs = text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c1c2c701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now our book is split up into 23 documents\n"
     ]
    }
   ],
   "source": [
    "num_documents = len(docs)\n",
    "\n",
    "print (f\"Now our book is split up into {num_documents} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d413b2d",
   "metadata": {},
   "source": [
    "Let's get our embeddings of those 26 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "898fc62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "vectors = embeddings.embed_documents([x.page_content for x in docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726f6dee",
   "metadata": {},
   "source": [
    "Now let's cluster our embeddings. There are a ton of clustering algorithms you can chose from. Please try a few out to see what works best for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55c8dce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivanimodi/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'embeddings' is a list or array of 768-dimensional embeddings\n",
    "\n",
    "# Choose the number of clusters, this can be adjusted based on the book's content.\n",
    "# I played around and found ~4 was the best.\n",
    "num_clusters = 5\n",
    "\n",
    "# Perform K-means clustering\n",
    "vectors_array = np.array(vectors)\n",
    "print(vectors_array.shape)\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42).fit(vectors_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891d82cd",
   "metadata": {},
   "source": [
    "The identified clusters offer an intriguing glimpse into the book's progression. As the narrative evolves, we can anticipate shifts in the clusters, reflecting the varying semantic contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "218dce05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 3, 3, 2, 0, 3, 3, 0, 1, 1, 1, 1, 0, 1, 0, 4, 4, 1, 1,\n",
       "       0], dtype=int32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9ccd8b",
   "metadata": {},
   "source": [
    "This is neat, but in any clustering task, visualizing them is quite compelling. Don't forget to incorporate colors.\n",
    "\n",
    "Additionally, we should perform dimensionality reduction to bring down the vectors from 768 dimensions to just 2. While this approach isn't rigorous data science, it aligns with our goal of achieving an 80% solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "95da2509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import warnings\n",
    "from warnings import simplefilter\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Perform t-SNE and reduce to 2 dimensions\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=10)\n",
    "vectors = np.array(vectors)\n",
    "reduced_data_tsne = tsne.fit_transform(vectors)\n",
    "\n",
    "# Plot the reduced data\n",
    "plt.scatter(reduced_data_tsne[:, 0], reduced_data_tsne[:, 1], c=kmeans.labels_)\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.title('Book Embeddings Clustered')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa4314b",
   "metadata": {},
   "source": [
    "Next, we should identify the vectors nearest to the cluster centroids (the central point).\n",
    "\n",
    "Below is a function that accomplishes this efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55f2f664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the embeddings closest to the centroids\n",
    "\n",
    "# Initialize a list to store indices of nearest points\n",
    "closest_indices = []\n",
    "\n",
    "# Iterate over all clusters\n",
    "for i in range(num_clusters):\n",
    "    \n",
    "    # Calculate distances from the current cluster's center\n",
    "    distances = np.linalg.norm(vectors - kmeans.cluster_centers_[i], axis=1)\n",
    "    \n",
    "    # Identify the index of the minimum distance (closest point)\n",
    "    closest_index = np.argmin(distances)\n",
    "    \n",
    "    # Store the identified index in the list\n",
    "    closest_indices.append(closest_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a44596",
   "metadata": {},
   "source": [
    "Now, arrange them in sequence (to ensure chunks are processed sequentially)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "679297ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 5, 6, 11, 18]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_indices = sorted(closest_indices)\n",
    "selected_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171c2b42",
   "metadata": {},
   "source": [
    "It's intersting to see which chunks pop up at most descriptive. \n",
    "\n",
    "Let's create our custom prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5552e6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_prompt = \"\"\"\n",
    "You will be given a single passage of a book. This section will be enclosed in triple backticks (```)\n",
    "Your goal is to give a concise summary of this section so that a reader will have a full understanding of what happened.\n",
    "Your response should be at least three paragraphs and fully encompass what was said in the passage.\n",
    "\n",
    "```{text}```\n",
    "Concise SUMMARY:\n",
    "\"\"\"\n",
    "map_prompt_template = PromptTemplate(template=map_prompt, input_variables=[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b568b94a",
   "metadata": {},
   "source": [
    "**In this example I will do the map reduce manually**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb5eb0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_chain = load_summarize_chain(llm=llm,\n",
    "                             chain_type=\"stuff\",\n",
    "                             prompt=map_prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e1ec38",
   "metadata": {},
   "source": [
    "Then go get your docs which the top vectors represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "781a686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_docs = [docs[doc] for doc in selected_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca5fc42",
   "metadata": {},
   "source": [
    "Let's loop through our selected docs and get a good summary for each chunk. We'll store the summary in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "84f50afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary #0 (chunk #0) - Preview:  The article discusses the economic potential of generative AI, a technology that could add trillions of dollars in value to the global economy. Generative AI has the potential to automate work activities that absorb 60-70% of employees' time, accele \n",
      "\n",
      "Summary #1 (chunk #5) - Preview:  This passage discusses the potential impact of generative AI on various business functions, including product discovery and search, sales, software engineering, and product R&D. Generative AI can personalize product discovery and search with multimo \n",
      "\n",
      "Summary #2 (chunk #6) - Preview:  This passage discusses the potential of generative AI in various industries, particularly in the field of research and development (R&D). The authors argue that generative AI has the potential to revolutionize R&D by enabling faster and more efficie \n",
      "\n",
      "Summary #3 (chunk #11) - Preview:  This passage discusses the potential for generative AI to accelerate technical automation and transform knowledge work. The authors analyze the capabilities of generative AI and how it can automate various work activities. They find that generative  \n",
      "\n",
      "Summary #4 (chunk #18) - Preview:  This passage discusses the potential impact of generative AI on the labor market. According to a study by McKinsey & Company, generative AI could automate up to 25% of current work tasks, with scenarios ranging from 15% to 35%, depending on differen \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make an empty list to hold your summaries\n",
    "summary_list = []\n",
    "\n",
    "# Loop through a range of the lenght of your selected docs\n",
    "for i, doc in enumerate(selected_docs):\n",
    "    \n",
    "    # Go get a summary of the chunk\n",
    "    chunk_summary = map_chain.run([doc])\n",
    "    \n",
    "    # Append that summary to your list\n",
    "    summary_list.append(chunk_summary)\n",
    "    \n",
    "    print (f\"Summary #{i} (chunk #{selected_indices[i]}) - Preview: {chunk_summary[:250]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e2220ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Summary #0 (from chunk #0) - Snippet:  The article discusses the economic potential of generative AI, a technology that has the ability to generate new and original content, such as text, music, and digital art. The authors estimate that generative AI could add $2.6 to $4.4 trillion in v \n",
      "\n",
      "Processed Summary #1 (from chunk #5) - Snippet:  This passage discusses the potential of generative AI to increase productivity in various industries, including marketing, sales, software engineering, and product R&D. Generative AI can help personalize product discovery and search, improve lead de \n",
      "\n",
      "Processed Summary #2 (from chunk #6) - Snippet:  This passage discusses the potential of generative AI in various industries, particularly in the field of research and development (R&D). The authors argue that generative AI can significantly improve productivity in R&D by enabling the rapid genera \n",
      "\n",
      "Processed Summary #3 (from chunk #11) - Snippet:  This passage discusses the potential for automation to increase productivity and enhance prosperity, with a focus on the impact of generative AI on the technical potential for automation. The authors estimate that with the acceleration in technical  \n",
      "\n",
      "Processed Summary #4 (from chunk #18) - Snippet:  This passage discusses the potential impact of generative AI on the labor market. Three studies are presented, each with a different approach to estimating the exposure of various occupations to AI automation. The first study, by Edward W. Felten, M \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list for storing summaries\n",
    "summaries = []\n",
    "\n",
    "# Iterate over the selected documents\n",
    "for idx, document in enumerate(selected_docs):\n",
    "    # Obtain a summary for the specific chunk\n",
    "    summarized_chunk = map_chain.run([document])\n",
    "    \n",
    "    # Add the summarized chunk to the summaries list\n",
    "    summaries.append(summarized_chunk)\n",
    "    \n",
    "    print (f\"Processed Summary #{idx} (from chunk #{selected_indices[idx]}) - Snippet: {summarized_chunk[:250]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fae1a72",
   "metadata": {},
   "source": [
    "Great, now that we have our list of summaries, let's get a summary of the summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4083431d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your total summary has 1135 tokens\n"
     ]
    }
   ],
   "source": [
    "summaries = \"\\n\".join(summaries)\n",
    "\n",
    "# Convert it back to a document\n",
    "summaries = Document(page_content=summaries)\n",
    "\n",
    "print (f\"Your total summary has {llm.get_num_tokens(summaries.page_content)} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b98e7321",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_prompt = \"\"\"\n",
    "You will be given a series of summaries from a book. The summaries will be enclosed in triple backticks (```)\n",
    "Your goal is to give a concise summary of what happened in the story.\n",
    "The reader should be able to grasp what happened in the book.\n",
    "\n",
    "```{text}```\n",
    "CONCISE SUMMARY:\n",
    "\"\"\"\n",
    "combine_prompt_template = PromptTemplate(template=combine_prompt, input_variables=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2930c26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_chain = load_summarize_chain(llm=llm,\n",
    "                             chain_type=\"stuff\",\n",
    "                             prompt=combine_prompt_template,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c6eda913",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = reduce_chain.run([summaries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "915628a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generative AI has the potential to significantly impact various industries and increase productivity, with an estimated value ranging from $2.6 trillion to $4.4 trillion. It can automate certain tasks, enhance productivity, and create novel product categories, leading to step changes in economic growth. The technology can also challenge existing business models and intellectual property laws.\n",
      "\n",
      "In the field of research and development (R&D), generative AI can improve productivity by enabling the rapid generation of design options, reducing the time required for physical testing, and optimizing test cases. It can also create novel product categories, leading to step changes in economic growth.\n",
      "\n",
      "The impact of generative AI on the labor market is significant, with highly-educated, highly-paid, white-collar occupations being most exposed to generative AI. It could increase labor productivity by 0.1% to 0.6% annually over the next ten to 20 years, depending on the difficulty level of tasks generative AI could perform, how many jobs are automated, and the speed of adoption.\n",
      "\n",
      "Overall, generative AI has the potential to revolutionize various industries and increase productivity, leading to significant economic growth. However, it also raises important questions about the impact on the labor market and the need for workers to adapt to new roles and technologies.\n"
     ]
    }
   ],
   "source": [
    "print (output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a1db73",
   "metadata": {},
   "source": [
    "Wow that was a long process, but you get the gist, hopefully we'll see some library abstractions in the coming months that do this automatically for us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8803be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab8944b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
